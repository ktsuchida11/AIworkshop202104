{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch04_05_tuing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI0fsjVO6AFQ"
      },
      "source": [
        "# チューニングのポイント　その1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IGVWl9A6AFR"
      },
      "source": [
        "### 実行前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgT4X9sQ6AFR",
        "outputId": "146421fa-a0fc-4622-a991-730f6ba3956f"
      },
      "source": [
        "# 日本語化ライブラリ導入\n",
        "!pip install japanize-matplotlib | tail -n 1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz7RoOHl6AFV"
      },
      "source": [
        "# 共通事前処理\n",
        "\n",
        "# 余分なワーニングを非表示にする\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 必要ライブラリのimport\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# matplotlib日本語化対応\n",
        "import japanize_matplotlib\n",
        "\n",
        "# データフレーム表示用関数\n",
        "from IPython.display import display\n",
        "\n",
        "# 表示オプション調整\n",
        "# numpyの浮動小数点の表示精度\n",
        "np.set_printoptions(suppress=True, precision=4)\n",
        "# pandasでの浮動小数点の表示精度\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "# データフレームですべての項目を表示\n",
        "pd.set_option(\"display.max_columns\",None)\n",
        "# グラフのデフォルトフォント指定\n",
        "plt.rcParams[\"font.size\"] = 14\n",
        "# 乱数の種\n",
        "random_seed = 123"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY824oLy6AFX"
      },
      "source": [
        "#### サンプルデータの読み込み\n",
        "乳がん疾患データ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cigL7Rf96AFY",
        "scrolled": true
      },
      "source": [
        "# サンプルデータの読み込み\n",
        "# (乳がん疾患データ)\n",
        "\n",
        "# データのロード\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# 入力データ: x (30次元)\n",
        "# 正解データ: y\n",
        "x = cancer.data\n",
        "y = cancer.target"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxmA-i9u6AFa",
        "outputId": "3cb12fab-b4a4-4083-de9b-1216d7258d8f"
      },
      "source": [
        "# サンプルデータの分割\n",
        "\n",
        "# データ分割のパラメータ\n",
        "test_size = 0.1\n",
        "\n",
        "# データ分割\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
        "    test_size=test_size, random_state=random_seed,\n",
        "    stratify=y)\n",
        "\n",
        "# 分割後サイズ確認\n",
        "print(x.shape)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 30)\n",
            "(512, 30)\n",
            "(57, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_QjsrYy6AFc"
      },
      "source": [
        "## チューニングのポイント1　アルゴリズムの選択\n",
        "\n",
        "最初に確認したいアルゴリズムを宣言して、リストにしておきます。リストをループさせて、各アリゴリズムの学習結果を確認します。\n",
        "\n",
        "実際は、アルゴリズム(ニューラルネットワーク)によっては、入力データを正規化する必要がありますが、決定木型モデルではこのやり方で行けます。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyUICaYY6AFe"
      },
      "source": [
        "# 複数アルゴリズムで精度を比較\n",
        "# 結果が同じになるようrandom_stateは同一にする\n",
        "\n",
        "# 線形回帰\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "algorithm1 = LogisticRegression(random_state=random_seed)\n",
        "\n",
        "# サポートベクターマシン(カーネル)\n",
        "from sklearn.svm import SVC\n",
        "algorithm2 = SVC(kernel='rbf', random_state=random_seed)\n",
        "\n",
        "# ニューラルネットワーク　\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "algorithm3 = MLPClassifier(hidden_layer_sizes=(100,100), random_state=random_seed)\n",
        "\n",
        "# 決定木\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "algorithm4 = DecisionTreeClassifier(random_state=random_seed)\n",
        "\n",
        "# ランダムフォレスト\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "algorithm5 = RandomForestClassifier(random_state=random_seed)\n",
        "\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "algorithm6 = XGBClassifier(random_state=random_seed)\n",
        "\n",
        "# アルゴリズムのリスト作成\n",
        "algorithms = [algorithm1, algorithm2, algorithm3, algorithm4, \n",
        "    algorithm5, algorithm6]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYNYBRO26AFg",
        "outputId": "c31225e3-f3f7-4169-d70c-86f9775633fe"
      },
      "source": [
        "# 複数アルゴリズムで精度比較\n",
        "for algorithm in algorithms:\n",
        "    \n",
        "    # 訓練データで学習\n",
        "    algorithm.fit(x_train, y_train)\n",
        "    \n",
        "    # 検証データで精度測定\n",
        "    score = algorithm.score(x_test, y_test)\n",
        "    \n",
        "    # アルゴリズム名取得\n",
        "    name = algorithm.__class__.__name__\n",
        "\n",
        "    # 精度とアルゴリズム名表示\n",
        "    print(f'score: {score:.4f}  {name}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score: 0.9649  LogisticRegression\n",
            "score: 0.8947  SVC\n",
            "score: 0.9649  MLPClassifier\n",
            "score: 0.9474  DecisionTreeClassifier\n",
            "score: 0.9298  RandomForestClassifier\n",
            "score: 0.9825  XGBClassifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9epWDxSEsOEI"
      },
      "source": [
        "各アルゴリズムの結果を確認すると、XGBoostが一番よさそうです。\n",
        "後ほど結果を検証する方法を紹介し、検証した結果と比べたいと思います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LgFU0xbs-HM"
      },
      "source": [
        "#### 1つの例だけでは面白くないので　アイリスデータセットでもやってみましょう。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWg26HxjtPyF"
      },
      "source": [
        "# ランダムフォレストのモデルを作るまで\n",
        "# サンプルデータの読み込み\n",
        "import seaborn as sns\n",
        "df_iris = sns.load_dataset(\"iris\")\n",
        "columns_i = ['がく片長', 'がく片幅', '花弁長', '花弁幅', '種別']\n",
        "df_iris.columns = columns_i\n",
        "# 入力データ x\n",
        "xi = df_iris[['がく片長', 'がく片幅', '花弁長', '花弁幅']]\n",
        "# 正解データ y\n",
        "yi = df_iris['種別']\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HpQsKKvuPx0",
        "outputId": "4e979828-931f-4f54-c46a-868c2a220c28"
      },
      "source": [
        "# サンプルデータの分割\n",
        "\n",
        "# データ分割のパラメータ\n",
        "test_size = 0.1\n",
        "\n",
        "# データ分割\n",
        "from sklearn.model_selection import train_test_split\n",
        "xi_train, xi_test, yi_train, yi_test = train_test_split(xi, yi, \n",
        "    test_size=test_size, random_state=random_seed,\n",
        "    stratify=yi)\n",
        "\n",
        "# 分割後サイズ確認\n",
        "print(xi.shape)\n",
        "print(xi_train.shape)\n",
        "print(xi_test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n",
            "(135, 4)\n",
            "(15, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoMrQDLTufwu",
        "outputId": "04688e0f-5e92-4558-92a3-074ee6676000"
      },
      "source": [
        "# 複数アルゴリズムで精度比較\n",
        "for algorithm in algorithms:\n",
        "    \n",
        "    # 訓練データで学習\n",
        "    algorithm.fit(xi_train, yi_train)\n",
        "    \n",
        "    # 検証データで精度測定\n",
        "    score = algorithm.score(xi_test, yi_test)\n",
        "    \n",
        "    # アルゴリズム名取得\n",
        "    name = algorithm.__class__.__name__\n",
        "\n",
        "    # 精度とアルゴリズム名表示\n",
        "    print(f'score: {score:.4f}  {name}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score: 1.0000  LogisticRegression\n",
            "score: 0.9333  SVC\n",
            "score: 0.9333  MLPClassifier\n",
            "score: 0.9333  DecisionTreeClassifier\n",
            "score: 1.0000  RandomForestClassifier\n",
            "score: 0.9333  XGBClassifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVzKwAQJvUjr"
      },
      "source": [
        "2つぐらい例を提示しておくと記憶に残りやすい"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RSvFAdJ6AFi"
      },
      "source": [
        "## チューニングのポイント2　ハイパーパラメータの最適化\n",
        "\n",
        "アルゴリズムによってハイパーパラメータは異なります。\n",
        "先ほどのアルゴリズムの選択では結果の悪かった\n",
        "サポートベクターカーネルのハイパーパラメータをチューニングしながら、最適化方法を確認します。\n",
        "\n",
        "※あまり結果の悪いアルゴリズムのチューニングは行わないが、大きく改善されるためわかりやすい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPRlb_QU6AFj",
        "outputId": "377c053d-7a50-4676-e2e7-bcfae0a4bf40"
      },
      "source": [
        "# デフォルトパラメータの確認\n",
        "algorithm = SVC(kernel='rbf', random_state=random_seed)\n",
        "print(algorithm)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=123, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhUceNTKwhJm"
      },
      "source": [
        "#### チューニングするハイパーパラメータのターゲットを予め決めておく必要がある\n",
        "まず、サポートベクターカーネルでチューニングするのは分類エリアの大きさを調整するgammaを調整します。\n",
        "チューニング値を明示的にリストにしてループさせ、その結果をみて最適値を探っていくことになります。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLjgd4gK6AFl",
        "outputId": "9e90468f-a4c4-4447-d749-a3fe50bdfcc2"
      },
      "source": [
        "# gammaの最適化\n",
        "algorithm = SVC(kernel='rbf', random_state=random_seed)\n",
        "\n",
        "#チューニング値を明示的にリスト化\n",
        "gammas = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
        "\n",
        "for gamma in gammas:\n",
        "    algorithm.gamma = gamma\n",
        "    algorithm.fit(x_train, y_train)\n",
        "    score = algorithm.score(x_test, y_test)\n",
        "    print(f'score: {score:.4f}  gamma: {gamma}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score: 0.6316  gamma: 1\n",
            "score: 0.6316  gamma: 0.1\n",
            "score: 0.6316  gamma: 0.01\n",
            "score: 0.9474  gamma: 0.001\n",
            "score: 0.9474  gamma: 0.0001\n",
            "score: 0.9474  gamma: 1e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgQ6avU2xU2x"
      },
      "source": [
        "次に、サポートベクターカーネルでチューニングするのはモデルの複雑さを調整するCを調整します。 チューニング値を明示的にリストにしてループさせ、その結果をみて最適値を探っていくことになります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGDQaEq96AFn",
        "outputId": "b48945aa-a2e3-431d-bef0-1f911f8c3e87"
      },
      "source": [
        "# Cの最適化\n",
        "# gammaは先ほど調べた最適値 0.001を採用\n",
        "#チューニング値を明示的にリスト化\n",
        "Cs = [1,  10,  100, 1000, 10000]\n",
        "for C in Cs:\n",
        "    algorithm = SVC(kernel='rbf', \n",
        "        gamma=0.001, C=C,\n",
        "        random_state=random_seed)\n",
        "    algorithm.fit(x_train, y_train)\n",
        "    score = algorithm.score(x_test, y_test)\n",
        "    print(f'score: {score:.4f}  C: {C}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score: 0.9474  C: 1\n",
            "score: 0.9298  C: 10\n",
            "score: 0.9298  C: 100\n",
            "score: 0.9298  C: 1000\n",
            "score: 0.9298  C: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6el6lbtyH8H",
        "outputId": "4dd9112d-2d80-41f3-9764-d350bde3d13c"
      },
      "source": [
        "# 複数アルゴリズムで精度を比較\n",
        "# 結果が同じになるようrandom_stateは同一にする\n",
        "# 線形回帰\n",
        "algorithm1 = LogisticRegression(random_state=random_seed)\n",
        "\n",
        "# サポートベクターマシン(カーネル)\n",
        "algorithm2 =  SVC(kernel='rbf', gamma=0.001, C=1, random_state=random_seed)\n",
        "\n",
        "# ニューラルネットワーク　\n",
        "algorithm3 = MLPClassifier(hidden_layer_sizes=(100,100), random_state=random_seed)\n",
        "\n",
        "# 決定木\n",
        "algorithm4 = DecisionTreeClassifier(random_state=random_seed)\n",
        "\n",
        "# ランダムフォレスト\n",
        "algorithm5 = RandomForestClassifier(random_state=random_seed)\n",
        "\n",
        "# XGBoost\n",
        "algorithm6 = XGBClassifier(random_state=random_seed)\n",
        "\n",
        "# アルゴリズムのリスト作成\n",
        "algorithms = [algorithm1, algorithm2, algorithm3, algorithm4, \n",
        "    algorithm5, algorithm6]\n",
        "\n",
        "# 複数アルゴリズムで精度比較\n",
        "for algorithm in algorithms:\n",
        "    \n",
        "    # 訓練データで学習\n",
        "    algorithm.fit(x_train, y_train)\n",
        "    \n",
        "    # 検証データで精度測定\n",
        "    score = algorithm.score(x_test, y_test)\n",
        "    \n",
        "    # アルゴリズム名取得\n",
        "    name = algorithm.__class__.__name__\n",
        "\n",
        "    # 精度とアルゴリズム名表示\n",
        "    print(f'score: {score:.4f}  {name}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score: 0.9649  LogisticRegression\n",
            "score: 0.9474  SVC\n",
            "score: 0.9649  MLPClassifier\n",
            "score: 0.9474  DecisionTreeClassifier\n",
            "score: 0.9298  RandomForestClassifier\n",
            "score: 0.9825  XGBClassifier\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqpTFwpmy_73"
      },
      "source": [
        "### これでどのアルゴリズムも甲乙つけがたくなったと思います。この結果をもとにさらに検証を行うことで、どのアルゴリズムを採用するかを決めることになります。\n",
        "次は、代表的な検証方法について、紹介し上記の結果と検証結果がどれくらい異なるかを確認します。\n"
      ]
    }
  ]
}